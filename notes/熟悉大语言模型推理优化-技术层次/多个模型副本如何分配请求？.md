---
created: '2025-10-19'
last_reviewed: null
next_review: '2025-10-19'
review_count: 0
difficulty: medium
mastery_level: 0.0
tags:
- 熟悉大语言模型推理优化-技术层次
- 熟悉大语言模型推理优化-技术层次/多个模型副本如何分配请求？.md
related_outlines: []
---
# 多个模型副本如何分配请求？

## 面试标准答案

请求分配主要通过负载均衡器实现，常见策略包括：1)轮询(Round Robin)简单但不考虑负载；2)最少连接(Least Connections)选择当前请求数最少的副本；3)加权轮询根据GPU性能分配权重；4)响应时间感知选择平均延迟最低的副本；5)哈希路由保证相同用户请求到同一副本。实际系统常用最少连接或响应时间感知策略，配合健康检查和故障转移。关键是平衡各副本负载，避免某些副本过载而其他空闲。

---

## 详细讲解

### 1. Round Robin (轮询)

```python
class RoundRobinScheduler:
    def __init__(self, num_replicas):
        self.num_replicas = num_replicas
        self.counter = 0
    
    def select_replica(self):
        replica = self.counter % self.num_replicas
        self.counter += 1
        return replica

# 优点: 简单、公平
# 缺点: 不考虑实际负载
```

### 2. Least Connections (最少连接)

```python
class LeastConnectionsScheduler:
    def __init__(self, num_replicas):
        self.active_requests = [0] * num_replicas
    
    def select_replica(self):
        return self.active_requests.index(min(self.active_requests))
    
    def on_request_start(self, replica_id):
        self.active_requests[replica_id] += 1
    
    def on_request_complete(self, replica_id):
        self.active_requests[replica_id] -= 1

# 优点: 动态负载均衡
# 缺点: 未考虑请求复杂度差异
```

### 3. Weighted Round Robin (加权轮询)

```python
class WeightedRoundRobinScheduler:
    def __init__(self, weights):
        # weights: [1.0, 1.0, 0.8, 0.8]  # 前两个GPU更强
        self.weights = weights
        self.total_weight = sum(weights)
        self.current = 0
    
    def select_replica(self):
        # 根据权重分布选择
        r = random.uniform(0, self.total_weight)
        cumsum = 0
        for i, w in enumerate(self.weights):
            cumsum += w
            if r < cumsum:
                return i
        return len(self.weights) - 1

# 适合: 异构GPU环境
```

### 4. Response Time Aware (响应时间感知)

```python
class ResponseTimeAwareScheduler:
    def __init__(self, num_replicas):
        self.avg_response_times = [0.0] * num_replicas
        self.request_counts = [0] * num_replicas
        self.ema_alpha = 0.2  # 指数移动平均系数
    
    def select_replica(self):
        # 选择平均响应时间最低的
        return min(range(len(self.avg_response_times)),
                   key=lambda i: self.avg_response_times[i] 
                                 if self.request_counts[i] > 0 
                                 else 0)
    
    def update_response_time(self, replica_id, response_time):
        # EMA更新
        if self.request_counts[replica_id] == 0:
            self.avg_response_times[replica_id] = response_time
        else:
            self.avg_response_times[replica_id] = (
                self.ema_alpha * response_time +
                (1 - self.ema_alpha) * self.avg_response_times[replica_id]
            )
        self.request_counts[replica_id] += 1

# 优点: 自适应性能差异
# 缺点: 冷启动问题
```

### 5. 哈希路由

```python
class HashBasedScheduler:
    def __init__(self, num_replicas):
        self.num_replicas = num_replicas
    
    def select_replica(self, user_id):
        # 一致性哈希
        return hash(user_id) % self.num_replicas

# 用途: 会话保持、缓存亲和性
# 缺点: 负载可能不均
```

### 6. 混合策略

```python
class HybridScheduler:
    def __init__(self, num_replicas):
        self.least_conn = LeastConnectionsScheduler(num_replicas)
        self.response_time = ResponseTimeAwareScheduler(num_replicas)
        self.active_counts = [0] * num_replicas
    
    def select_replica(self, request_metadata=None):
        # 1. 如果有user_id且需要会话保持
        if request_metadata and request_metadata.get('sticky_session'):
            return hash(request_metadata['user_id']) % self.num_replicas
        
        # 2. 过滤掉过载的副本
        candidates = [i for i in range(self.num_replicas)
                     if self.active_counts[i] < MAX_CONCURRENT]
        
        if not candidates:
            candidates = list(range(self.num_replicas))
        
        # 3. 在候选中选择响应时间最好的
        return min(candidates, 
                   key=lambda i: self.response_time.avg_response_times[i])

# 实用的综合策略
```

### 7. 健康检查与故障转移

```python
class HealthAwareScheduler:
    def __init__(self, num_replicas):
        self.healthy = [True] * num_replicas
        self.scheduler = LeastConnectionsScheduler(num_replicas)
    
    def health_check(self):
        for i in range(len(self.healthy)):
            try:
                # 发送健康检查请求
                response = ping_replica(i)
                self.healthy[i] = response.ok
            except:
                self.healthy[i] = False
    
    def select_replica(self):
        # 只从健康的副本中选择
        healthy_replicas = [i for i, h in enumerate(self.healthy) if h]
        
        if not healthy_replicas:
            raise Exception("No healthy replicas available")
        
        # 在健康副本中使用负载均衡
        return min(healthy_replicas, 
                   key=lambda i: self.scheduler.active_requests[i])

# 关键: 高可用性
```

### 8. 实际系统示例

**Kubernetes Ingress**:
```yaml
kind: Service
spec:
  selector:
    app: llm-inference
  sessionAffinity: ClientIP  # 会话保持
  
---
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/load-balance: "least_conn"
```

**vLLM**:
```python
# 内置的请求调度
# 使用最少连接 + 抢占式调度
```

### 9. 性能对比

```
测试: GPT-J 6B, 4副本, 混合请求

Round Robin:
- 平均延迟: 250ms
- P99延迟: 450ms
- 吞吐: 80 req/s

Least Connections:
- 平均延迟: 180ms ✓
- P99延迟: 320ms ✓
- 吞吐: 95 req/s ✓

Response Time Aware:
- 平均延迟: 170ms ✓✓
- P99延迟: 300ms ✓✓
- 吞吐: 100 req/s ✓✓

推荐: Least Connections 或 Response Time Aware
```

合理的请求分配策略可以显著提升推理系统的性能和可靠性。


---

## 相关笔记
<!-- 自动生成 -->

- [请求路由策略有哪些（轮询、最少连接、性能感知）？](notes/熟悉大语言模型推理优化-技术层次/请求路由策略有哪些（轮询、最少连接、性能感知）？.md) - 相似度: 39% | 标签: 熟悉大语言模型推理优化-技术层次, 熟悉大语言模型推理优化-技术层次/请求路由策略有哪些（轮询、最少连接、性能感知）？.md

