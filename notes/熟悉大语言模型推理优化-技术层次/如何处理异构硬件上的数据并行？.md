# 如何处理异构硬件上的数据并行？

## 面试标准答案

异构硬件数据并行的关键是根据GPU性能差异调整负载分配。主要方法：1)加权路由，根据GPU计算能力(FLOPS)、显存大小设置权重；2)动态调整，实时监控GPU利用率和响应时间，调整分配比例；3)分层调度，将复杂请求分配给强GPU，简单请求分配给弱GPU；4)容量感知，根据显存限制调整batch size；5)亲和性绑定，固定某些请求类型到特定GPU。实践中常用加权最少连接策略，配合动态监控和自适应调整。

---

## 详细讲解

### 1. 异构环境示例

```python
# 混合GPU配置
gpus = [
    {'id': 0, 'model': 'A100', 'memory': 80, 'tflops': 312},
    {'id': 1, 'model': 'A100', 'memory': 80, 'tflops': 312},
    {'id': 2, 'model': 'V100', 'memory': 32, 'tflops': 125},
    {'id': 3, 'model': 'V100', 'memory': 32, 'tflops': 125},
]

# 性能差异: A100 是 V100 的 2.5x
```

### 2. 加权调度

```python
class HeterogeneousScheduler:
    def __init__(self, gpu_configs):
        self.gpus = gpu_configs
        self.weights = self.calculate_weights()
    
    def calculate_weights(self):
        # 基于FLOPS计算权重
        total_flops = sum(g['tflops'] for g in self.gpus)
        weights = [g['tflops'] / total_flops * len(self.gpus) 
                   for g in self.gpus]
        return weights
    
    def select_gpu(self):
        # 加权随机选择
        return random.choices(
            range(len(self.gpus)),
            weights=self.weights
        )[0]

# 结果: A100分配67%请求, V100分配33%
```

### 3. 动态调整

```python
class AdaptiveScheduler:
    def __init__(self, gpus):
        self.gpus = gpus
        self.weights = [1.0] * len(gpus)
        self.response_times = [[] for _ in gpus]
    
    def update_weights(self):
        # 基于实际性能调整
        avg_times = [
            np.mean(times) if times else 1.0 
            for times in self.response_times
        ]
        
        # 倒数作为权重(更快的GPU权重更大)
        min_time = min(avg_times)
        self.weights = [min_time / t for t in avg_times]
    
    def record_response(self, gpu_id, time):
        self.response_times[gpu_id].append(time)
        if len(self.response_times[gpu_id]) > 100:
            self.response_times[gpu_id].pop(0)
        
        # 定期更新权重
        if sum(len(t) for t in self.response_times) % 50 == 0:
            self.update_weights()
```

### 4. 容量感知调度

```python
def capacity_aware_scheduling(request, gpus):
    required_memory = estimate_memory(request)
    
    # 过滤显存足够的GPU
    capable_gpus = [
        g for g in gpus 
        if g['available_memory'] >= required_memory
    ]
    
    if not capable_gpus:
        # 等待或拒绝
        return None
    
    # 在合格GPU中选择最空闲的
    return min(capable_gpus, 
               key=lambda g: g['current_load'])
```

### 5. 请求分层

```python
class TieredScheduler:
    def __init__(self, gpu_tiers):
        # gpu_tiers = {'high': [0,1], 'low': [2,3]}
        self.tiers = gpu_tiers
    
    def route_request(self, request):
        complexity = estimate_complexity(request)
        
        if complexity > THRESHOLD_HIGH:
            # 复杂请求 → 高性能GPU
            tier = self.tiers['high']
        else:
            # 简单请求 → 低性能GPU
            tier = self.tiers['low']
        
        # 在tier内负载均衡
        return self.select_from_tier(tier)
```

### 6. 批处理大小调整

```python
# 根据GPU能力调整batch size
batch_sizes = {
    'A100': 32,  # 强GPU用大batch
    'V100': 16,  # 弱GPU用小batch
    'T4': 8,
}

def get_batch_size(gpu_model):
    return batch_sizes.get(gpu_model, 16)
```

### 7. 实际案例

```python
# 配置: 4×A100 + 4×V100
策略:
1. A100处理长序列(>1024)和大batch
2. V100处理短序列(<512)和小batch  
3. 动态监控，自动调整

结果:
- A100利用率: 85%
- V100利用率: 82%
- 总吞吐提升35% vs 均匀分配
```

### 8. 最佳实践

```python
heterogeneous_config = {
    'enable_weighted_routing': True,
    'weight_calculation': 'dynamic',  # 或 'static'
    'monitoring_interval': 10,  # 秒
    'capacity_aware': True,
    'request_tiering': True,
    'auto_adjust_batch_size': True,
}
```

### 性能提升

```
均匀分配:
- A100: 50%利用率 (浪费)
- V100: 100%利用率 (过载)
- 总吞吐: 受限于V100

加权分配:
- A100: 85%利用率 ✓
- V100: 80%利用率 ✓
- 总吞吐: +40% ✓
```

异构环境需要智能调度来充分发挥各GPU的能力，避免性能浪费。

