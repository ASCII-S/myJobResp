---
created: '2025-10-19'
last_reviewed: '2025-10-19'
next_review: '2025-10-19'
review_count: 0
difficulty: medium
mastery_level: 0.0
tags:
- 熟悉大语言模型推理优化-技术层次
- 熟悉大语言模型推理优化-技术层次/如何为给定的模型和硬件选择最优的并行组合？.md
related_outlines: []
---

# 如何为给定的模型和硬件选择最优的并行组合？

## 面试标准答案

选择并行策略需考虑：1)模型大小vs GPU显存-单卡放不下需模型并行；2)GPU数量和拓扑-节点内优先TP，跨节点用PP；3)batch size要求-小batch不适合PP；4)延迟vs吞吐优先级-延迟敏感减少PP深度；5)通信带宽-NVLink支持TP，IB适合PP+DP。通用规则：<7B用纯DP，7-70B用TP+DP，>70B用TP+PP+DP，节点内TP=8，跨节点PP=节点数。实际需profiling验证和调优。

---

## 详细讲解

### 决策流程

```python
def select_parallelism_strategy(
    model_size_b,
    num_gpus,
    gpu_memory_gb,
    num_nodes,
    batch_size,
    priority='throughput'
):
    # Step 1: 能否单卡部署
    if model_size_b * 2 < gpu_memory_gb:  # 2x for activations
        return {'DP': num_gpus, 'TP': 1, 'PP': 1}
    
    # Step 2: 节点内可否容纳
    gpus_per_node = 8
    if model_size_b * 2 < gpu_memory_gb * gpus_per_node:
        # 单节点，使用TP
        return {
            'TP': min(8, num_gpus),
            'DP': num_gpus // 8,
            'PP': 1
        }
    
    # Step 3: 需要多节点
    if batch_size < 16:
        # 小batch不适合深流水线
        return {
            'TP': 8,
            'PP': min(4, num_nodes),
            'DP': num_gpus // (8 * PP)
        }
    else:
        # 大batch可用深流水线
        return {
            'TP': 8,
            'PP': num_nodes,
            'DP': 1
        }
```

### 实际案例

```python
# LLaMA-7B (4 GPUs)
model_size = 7
gpu_mem = 80
→ 策略: DP=4 (纯数据并行)

# LLaMA-70B (16 GPUs, 2节点)
model_size = 70
→ 策略: TP=8, DP=2 (节点内TP，跨节点DP)

# GPT-3-175B (64 GPUs, 8节点)
model_size = 175
→ 策略: TP=8, PP=8, DP=1

# GPT-4-1T (1024 GPUs, 128节点)
model_size = 1000
→ 策略: TP=8, PP=32, DP=4
```

### 约束条件

```python
# 硬约束
assert TP * PP * DP == total_gpus
assert model_params / TP / PP < gpu_memory

# 软约束（优化目标）
# 1. TP <= 8 (单节点)
# 2. PP深度适中 (避免气泡)
# 3. 通信最小化
```

### Profiling验证

```python
# 测试候选配置
candidates = [
    {'TP': 8, 'PP': 4, 'DP': 2},
    {'TP': 4, 'PP': 8, 'DP': 2},
    {'TP': 8, 'PP': 8, 'DP': 1},
]

best_config = None
best_throughput = 0

for config in candidates:
    throughput = benchmark(model, config)
    if throughput > best_throughput:
        best_throughput = throughput
        best_config = config
```

选择并行策略需要理论分析+实际测试相结合。


---

## 相关笔记
<!-- 自动生成 -->

暂无相关笔记

