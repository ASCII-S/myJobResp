---
created: '2025-10-19'
last_reviewed: '2025-10-19'
next_review: '2025-10-19'
review_count: 0
difficulty: medium
mastery_level: 0.0
tags:
- cuda
- cuda/Global_Memory.md
related_outlines: []
---

# 全局内存（Global Memory）

## 基本特性

* **容量**：GPU 显存的主要部分，通常几 GB 到几十 GB
* **可见性**：所有线程都可以访问，包括不同 block 的线程
* **延迟**：几百个时钟周期，是所有内存类型中最慢的
* **带宽**：现代 GPU 可达 1-2 TB/s，但需要合理的访问模式才能充分利用

## 面试常见问题与回答

### Q1: 全局内存的特点是什么？
**A**: 全局内存是 GPU 上容量最大的内存，所有线程都可以访问，但延迟最高（几百 cycle）。虽然带宽很高（TB/s 级别），但需要通过合并访问等优化手段才能充分利用。

### Q2: 什么是合并访问（Coalesced Access）？
**A**: 当 warp 内的 32 个线程访问连续的内存地址时，硬件可以将多个内存请求合并为少数几个内存事务，大大提高内存带宽利用率。比如 thread 0 访问 addr[0]，thread 1 访问 addr[1]...thread 31 访问 addr[31]，这样可以合并为一个 128 字节的事务。

### Q3: 如果内存访问不合并会怎样？
**A**: 会导致严重的性能问题。最坏情况下，warp 内 32 个线程访问 32 个不连续的地址，需要 32 个独立的内存事务，带宽利用率降到理论峰值的 1/32，严重影响性能。

### Q4: 如何优化全局内存访问？
**A**: 
1. **保证合并访问**：让 warp 内线程访问连续地址
2. **内存对齐**：确保访问地址按 128 字节对齐
3. **使用共享内存做缓存**：将频繁访问的数据先加载到共享内存
4. **避免不规则访问模式**：如跨步访问、随机访问等

## 什么是内存事务

* **定义**：一次 **warp 内存访问请求**，在硬件层面上会被翻译成若干次 **内存事务**，即对显存（global memory）的读或写操作单元。
* **大小**：现代 NVIDIA GPU 通常以 **32、64 或 128 字节**为一个事务单位（具体依架构和数据类型）。
* **工作机制**：

  * warp 内 32 个线程同时请求数据；
  * 如果这些访问地址连续、对齐（比如 thread 0 访问 addr0，thread 1 访问 addr0+4，… thread 31 访问 addr0+124），硬件会把它们合并为 **一个 128B 事务**；
  * 如果地址分散，比如 thread 0 访问 addr0，thread 1 访问 addr1000，warp 内可能需要 **32 个事务**都只访问4字节 才能完成一次加载。
  * 由于一个内存事务的最小值远远大于一个数据元素的大小（128B），因此如果不连续的访问，启动多个事务，其一个内存事务的利用率可能只有1/128。

---

## 为什么事务数量很重要

* **带宽利用率**：事务越少，带宽利用率越高。一次事务可以把整块数据搬上来，多个线程共享。
* **延迟隐藏**：更多事务 = 更多等待，warp 执行会拖慢。

